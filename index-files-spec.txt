Oznaczenia:
    u8, u16, u24, u32, u64:
        liczby bez znaku, 8-, 16-, 24-, 32, 64-bitowe, zapisywane od najmniej
        znaczącego bajtu (czyli w normalnym intelowskim little-endian).
    uv:
        unsigned variable length coding: dzieli bloki na 7-bitowe kawałki,
        koduje każdy kawałek jako jeden bajt z najwyższym bitem ustawionym
        dla oznaczenia wszystkich kawałków poza ostatnim; kawałki są
        kodowane od najstarszego do najmłodszego.
    float:
        float (ieee 754)
    utf8:
        napis w utf-8
    utf8z:
        napis w utf-8 zakończony znakiem \x00 (znak ten nie jest poprawny w
        utf-8, więc można go użyć jako terminatora).

--------------------------------------------------------------------------------
0. PROCEDURA BUDOWANIA INDEKSU

 - Tokenizacja wikipedii. Dane wejściowe z wikipedii zamienia się na taki
   format, w którym każdy artykuł jest zapisany w dwóch liniach, gdzie
   pierwsza linia zawiera tytuł, a druga tekst artykułu. Na tym etapie
   usuwamy wszystkie zbędne znaki oraz formujemy termy; zarówno w tytule,
   jak i w tekście termy są oddzielone pojedynczą spacją.
 
 - Tworzenie listy tytułów artykułów. Na podstawie ztokenizowanej wikipedii
   bardzo łatwo stworzyć pierwszy plik indeksu: tytuły artykułów (TITL).

 - Tworzenie korpusu (CORP). Na podstawie ztokenizowanej wikipedii oraz
   morfologika tworzymy korpus. Jest to plik oparty na tabeli hashującej,
   który zawiera wszystkie termy wikipedii oraz  morfologika oraz umożliwia
   łatwą zamianę ich na liczby. Plik ten daje nam wyobrażenie o zbiorze
   termów w danych wejściowych oraz gwarantuje, że żadne słowo już nigdy
   nas nie zaskoczy.

 - Digitizacja. Ztokenizowaną wikipedię zamieniamy na format binarny, to 
   znaczy zamieniamy kolejne tokeny na trójki (id_tokenu, nr_dokumentu,
   nr_słowa_w_dokumencie). id_tokenu jest wyznaczane przez korpus.

 - Odwracanie. Zdigitizowana wikipedia jest sortowana leksykograficznie
   dzięki czemu powstaje (nieco spasiony) pozycyjny indeks odwrócony.

 - Tworzenie indeksów i słownika. Na podstawie poprzedniego kroku łatwo
   stworzyć plik pozycyjnego indeksu odwróconego (IDXP) oraz
   słownika (DICT). Z wykorzystaniem morfologika można też już stworzyć 
   plik indeksu lematyzowanego (IDXL), jakkolwiek chyba nie jest to proste.

 - Przycinanie. Być może wzięcie do korpusu morfologika + wikipedii było
   nieco na wyrost. Na końcu możemy usunąć ze słownika wszystkie słowa,
   które mają puste listy postingowe.

 - Szczęśliwy koniec.

... 0a. Lematyzacja

Jasne jest, że spotkawszy słowo w tekście chcemy je utożsamić ze wszystkimi
jego formami bazowymi (lub, jeśli takowych nie posiada, jedynie z nim samym).
Jednocześnie w specyfikacji zadania napisano, że "pojawienie się słowa w
zapytaniu oznacza zapytanie o którąkolwiek z jego form bazowych"! Oznacza to,
że jeżeli w tekście pojawia się słowo "kotami", to utożsamiamy je ze słowem
"kot", zaś użytkowik może wpisać "kotach".  Możliwe są dwa podejścia do
problemu (przynajmniej ;).
  1. Indekser wykonuje jednokrotnie lematyzację, a wyszukiwarka zamienia
     term 't' z zapytania na 't1' or 't2' or 't3', gdzie 't1', 't2', 't3'
     są formami bazowymi termu 't'. W tej wersji wyszukiwarka musi używać
     morfologika oraz wykonywać istotnie więcej merge-ów niż pojawia się
     w zapytaniu.
  2. Indekser wykonuje lematyzację podwójnie, to znaczy gdy widzi term 't',
     rozpatruje wszystkie jego formy bazowe 't1', 't2', 't3', a dla każdej
     z nich rozpatruje wszystkie formy pochodne, czyli 't11', 't12', 't13',
     't21', 't22', 't31', 't32' oraz indeksuje dokument pod wszystkimi tymi
     adresami. Wtedy wyszukiwarka może sięgnąć po prostu do jednej listy
     w indeksie.
Ze względu na optymalizację czasu wyszukiwania korzystniejsze jest podejście
drugie. Niestety, naiwna implementacja pociąga za sobą potężny rozrost
indeksu: jeżeli słowo ma dwie formy bazowe i są to dwa rzeczowniki, to
każdy z tych rzeczowników ma przynajmniej siedem form pochodnych (przypadki),
czyli jeden dokument zostanie zindeksowany czternaście razy!
Aby zapobiec takiej sytuacji, można zauważyć, że większość słów ma tylko
jedną formę podstawową. W szczególności prawie wszystkie odmiany słowa
"kot", które może wpisać użytkownik, jako jedyną formę podstawową mają
właśnie słowo "kot". W związku z tym ich listy postingowe będą takie same
(i będą zawierały wszystkie wystąpienia pochodnych słowa kot w wikipedii).
W związku z tym, można pamiętać tylko jedną taką listę postingową i 
podpiąć ją pod wszystkie słowa, które jako jedyną formę podstawową mają
słowo "kot".


::: problem:
WIKIPEDIA             F. BAZOWE          UŻYTKOWNIK


                         .1.
             ,---------> .2.
             |           .3.         
in: 2+4+8 ---+---------> .4. >---.  
             |           .5.     | 
             |           .6. >---+----->  wynik: 4+6+9
             |           .7.     |  
             `---------> .8.     |     
                         .9. >---'   

::: optymalizacja:
WIKIPEDIA             F. BAZOWE          UŻYTKOWNIK


                         ....
               ,-------> kota >--+--------> kota       osobna lista postingowa
              /          ....    |      --> kotki   \
kota --------<           ....   /      +--> koty     |
              \          ....   |     +---> kotu     | wspólna
               +-------> kot  >-^----+----> kotom    | lista
              /          ....         +---> kotem    | postingowa
xxx ---------'           ....          +--> kotów    |
                         ....           --> kocie   /

... 0a. Plik korpusu:

u32: magiczna liczba ('CORP')
3*u32: parametry a,b,n, funkcji hashującej (słowo traktujemy jako liczbę
       zapisaną w systemie 256-tkowym od najstarszej do najmłodszej pozycji;
       hashem słowa x jest wartość ((ax+b) % mod) % n, gdzie mod = 2012345669.
       ilością kubełków jest n.
u8[]: ilości słów w kubełkach
u8[]: długości kolejnych słów
utf8[]: słowa

... 0b. Plik zdigitizowany:

u64[]: ciąg symboli, gdzie każdy symbol składa się z:
        - 25 bitów: id termu według korpusu (msb)
        - 20 bitów: id dokumentu
        - 19 bitów: offset termu w dokumencie (lsb)

... 0c. Plik aliasów:

u32: magiczna liczba ('ALIA')
u32: ilość słów
u32[]: tablica aliasów słów

... 0d. Plik binarnego morfologika:

u32: magiczna liczba ('MORF')
u32: ilość słów
dla każdego słowa:
    u32: id słowa na dolnych 24 bitach, ilość baz na górnych 8 bitach
    u32[]: id kolejnych baz słowa

--------------------------------------------------------------------------------
1. TYTUŁY ARTYKUŁÓW

u32: magiczna liczba ('TITL')
u32: ilość artykułów
float[]: pageranki artykułów
u16[]: ilości termów w artykułach
utf8z[]: tytuły artykułów

Rozmiar pliku: około 20MB. Struktura przewidziana do wczytania wszystkiego
do pamięci (stąd brak prostego dostępu do n-tego dokumentu).

--------------------------------------------------------------------------------
2. SŁOWNIK

u32: magiczna liczba ('DICT')
3*u32: parametry a,b,n, funkcji hashującej (jak w korpusie)
u32: ilość list lematyzowanych
u8[]: ilość słów w kubełku
dla każdego kubełka:
    dla każdego słowa:
        u24: numer listy lematyzowanej
        u8: długość słowa na dolnych 7 bitach,
            ósmy bit ustawiony oznacza stopword
dla każdej listy pozycyjnej:
    uv: długość w bajtach
    uv: ilość wpisów
dla każdej listy lematyzowanej:
    uv: długość w bajtach
    uv: ilość wpisów
dla każdego słowa:
    utf8: słowo

Rozmiar pliku: około 66MB. Struktura zrobiona tak, aby można było wczytać
całość do pamięci. Kolejność słów wyznacza kolejność w indeksie pozycyjnym
(ale nie w lematyzowanym), gdzie każde słowo ma swoją własną listę. W indeksie
lematyzowanym listy mogą być współdzielone, to znaczy wiele słów może wskazywać
na tą samą listę.

--------------------------------------------------------------------------------
3. INDEKS LEMATYZOWANY

u32: magiczna liczba ('IDXL')
dla każdego słowa:
    u24: pierwszy dokument
    uv: ilość wystąpień termu w pierwszym dokumencie
    dla każdego kolejnego dokumentu:
        uv: różnica między numerami kolejnych dokumentów
        uv: ilość wystąpień termu w dokumencie

--------------------------------------------------------------------------------
4. INDEKS POZYCYJNY

u32: magiczna liczba ('IDXP')
dla każdego słowa (w kolejności takiej jak w słowniku)
    u32: długość w bajtach opisu dokumentów (pola z gwiazdką)
    u24: pierwszy dokument (*)
    uv: długość w bajtach listy pozycyjnej pierwszego dokumentu (*)
    dla każdego kolejnego dokumentu:
        uv: różnica między numerami dokumentów (*)
        uv: długość w bajtach listy pozycyjnej (*)
    dla każdego dokumentu:
        uv: pozycja pierwszego wystąpienia słowa w dokumencie
        uv[]: różnice między kolejnymi pozycjami wystąpień słowa

W słowniku dla list pozycyjnych "ilość wpisów" oznacza ilość _dokumentów_,
natomiast "długość w bajtach" oznacza długość w bajtach całego powyższego
dla jednego termu.

Przykładowa lista pozycyjna:
W słowniku zapisano "ilość wpisów" = 3, "długość w bajtach" = 21

09 00 00 00 : długość w bajtach opisu dokumentów (z gwiazdkami) 

fa 03 01    : numer pierwszego dokumentu (66554) (*)
03          : długość w bajtach pierwszej listy pozycyjnej (z plusikami) (*)
73          : offset drugiego dokumentu (66669) (*)
01          : długość w bajtach drugiej listy pozycyjnej (z iksami) (*)
83 6a       : offset trzeciego dokumentu (67159) (*)
04          : długość w bajtach trzeciej listy pozycyjnej (z hashami) (*)

ca 3f       : pozycja pierwszego wystąpienia w pierwszym dokumencie (9535) (+)
05          : offset drugiego wystąpienia w pierwszym dokumencje (9540) (+)

01          : pozycja pierwszego wystąpienia w drugim dokumencie (1) (x)

3d          : pozycja pierwszego wystąpienia w trzecim dokumencie (61) (#)
8a 8f 83    : offset drugiego wystąpienia w trzecim dokumencie (3904) (#)

